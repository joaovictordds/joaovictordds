{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codigos-python.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Vlm5X2lL_Za",
        "txokNsEBlUjO",
        "NcvXeqY5XRZD",
        "9ajPFP3_2Am2",
        "u9Vd3J5GIU0G",
        "phzWFHFv7DOQ",
        "qUWFkNrsJjnm",
        "Huqq71iw7fKf",
        "2DQDTtTfpEzv",
        "wwNlj62XV4l9",
        "KkwKyyOum89h",
        "iEWx7KJtdgLd",
        "bUfia-09IU0b",
        "cALTHXaMIU0c",
        "vg59BIahIU0c",
        "Wdr6Pqn8IU0d",
        "hBf1Lut3IU0h"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "af573f283834de0d94267a2f349eb6a57bfc80fc16df6f4176b3eb1c7a5367fc"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaovictordds/joaovictordds/blob/Deploy/codigos_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Vlm5X2lL_Za"
      },
      "source": [
        "### Carregando dados no notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuPo8ODhL9Ee"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1qwUqHRwNTz"
      },
      "source": [
        "pd.set_option('display.max_columns', None) # Codigo para mostrar todas as colunas do dataset.\n",
        "\n",
        "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "caminho = 'nome_arquivo.csv'\n",
        "\n",
        "dados = pd.read_csv(url, delimiter = ' ', header = None)  # Sem cabe√ßalho\n",
        "dados = pd.read_csv(caminho, sep=';', encoding='ISO-8859-1', low_memory=False)\n",
        "# Especificando o 'type' da coluna pelo nome da coluna ao imputar a base (para bases de poucas colunas)\n",
        "base_de_dados = pd.read_csv(caminho, dtypes= {'nome_coluna':str, 'nome_coluna':int, 'nome_coluna':str, 'nome_coluna':float})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ1rhZUaIUzy"
      },
      "source": [
        "# renomeando colunas\n",
        "nomes = ['conta', 'dura√ß√£o', 'historico', 'motivo', 'quantia', \n",
        "         'poupan√ßa', 'emprego', 'taxa', 'status', 'garantia', \n",
        "         'residencia', 'propriedades', 'idade', 'financiamentos', 'moradia', \n",
        "         'creditos', 'trabalho', 'dependentes', 'telefone', 'estrangeiro', 'pagador']\n",
        "         \n",
        "dados.columns = nomes\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txokNsEBlUjO"
      },
      "source": [
        "### Explorando Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLUN8INuIUzz"
      },
      "source": [
        "import dtale \n",
        "import dtale.app as detalhe\n",
        "\n",
        "detalhe.USE_NGROK = True\n",
        "detalhe.show(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6olhmnpYY6t"
      },
      "source": [
        "import pandas_profiling\n",
        "dados.profile_report() # Mostra uma rela√ß√£o mais detalhada que a .describe()/.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BITDgxNlIUz0"
      },
      "source": [
        "import dataprep\n",
        "from dataprep.eda import *\n",
        "create_report(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJHJtVhBrHJj"
      },
      "source": [
        "import sweetviz as sv\n",
        "eda = sv.analyze(source = dados, target_feat = 'Exited')\n",
        "eda.show_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhsbADN2IUz1"
      },
      "source": [
        "from autoplotter import run_app\n",
        "#run_app(dados, mode = 'inline')\n",
        "run_app(dados, mode = 'external')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJhP8R1YcaU"
      },
      "source": [
        "from google.colab.data_table import DataTable\n",
        "DataTable(dados.T.round(2)) # mostra os dados em forma de tabela (Aqui usei .T para transpor e round pra 2 casas decimais)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQM2VP9nLfkV"
      },
      "source": [
        "base_de_dados.describe() # Mostra uma descri√ß√£o estatistica das colunas num√©ricas que encontrar.\n",
        "df.describe(include=['object']) # Mostra a descri√ß√£o das categ√≥ricas tamb√©m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pwxRsl6rP3b"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vcxYqACIUz2"
      },
      "source": [
        "# Buscando valores\n",
        "df['new_col'].where(df['new_col'] > 0 , 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5mtHaEcIUz3"
      },
      "source": [
        "# Est√° em\n",
        "years = ['2010','2014','2017']\n",
        "df[df.year.isin(years)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHodECB3L4Ce"
      },
      "source": [
        "sns.pairplot(base_de_dados[[\"coluna1\", \"coluna2\", \"coluna3\", \"colunaX\"]], diag_kind=\"kde\"); # Vendo a correla√ß√£o das variaveis selecionadas entre elas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbSBayDjA_4m"
      },
      "source": [
        "base_de_dados[\"Cilindros\"].value_counts() / len(dados) # Distribui√ß√£o da categoria"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CDBRnZoprsb"
      },
      "source": [
        "sns.countplot(dataset['aprovacao_emprestimo']); # conta as info da variavel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rMLVdBZlOw1"
      },
      "source": [
        "# Resumo grafico boxplot\n",
        "sns.boxplot(base_de_dados['coluna']).set_title('titulo_col')\n",
        "# vertical\n",
        "dataset.boxplot(column='emprestimo', vert=False );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "danHjl5tlbO3"
      },
      "source": [
        "# Resumo grafico histograma\n",
        "sns.histplot(base_de_dados['coluna']).set_title('titulo_col')\n",
        "# linha m√©dia\n",
        "sns.histplot(dataset['emprestimo'], bins=50, kde=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf9geUBlqMWd"
      },
      "source": [
        "# V√°rios graficos\n",
        "sns.pairplot(dataset, hue='aprovacao_emprestimo'); # kind='reg' √© a reta de regress√£o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6aSABfqtyRG"
      },
      "source": [
        "# Grafico Pizza\n",
        "dados['Balance'].value_counts().plot(kind ='pie')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQjSTBsGqDcc"
      },
      "source": [
        "# Grafico de dispersao\n",
        "sns.scatterplot(data=dataset, x=\"emprestimo\", y=\"renda\");\n",
        "#sns.scatterplot(data=dataset, x=\"emprestimo\", y=\"renda\", hue='aprovacao_emprestimo');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsJNBhjplecg"
      },
      "source": [
        "#exibindo dados de forma gr√°fica para analisar correla√ß√µes entre os dados\n",
        "sns.heatmap(base_de_dados.corr(), annot=True, cmap='Greens')\n",
        "# print(dataset.corr()) # aqui mostra a mesma correla√ß√£o s√≥ que em formato tabela."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jyOvUuPJ3kM"
      },
      "source": [
        "# Correla√ß√£o em formato tabela\n",
        "dados.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI2z5YhkBjNa"
      },
      "source": [
        "##pairplots to get an intuition of potential correlations\n",
        "sns.pairplot(base_de_dados[[\"MPG\", \"Cilindros\", \"Autonomia\", \"Peso\", \"cv\"]], diag_kind=\"kde\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ1vLPrvzxV0"
      },
      "source": [
        "base_de_dados.sort_values(by='COl1', ascending=False) # Ordena o dataset pela coluna selecionada e do maior para o menor."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTIaRC3-zxbE"
      },
      "source": [
        "base_de_dados.sort_values(by=['COl1','col4'], ascending=False) # Ordena o dataset pelas colunas selecionadas e do maior pro menor depois."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37MjQU1Kzxd4"
      },
      "source": [
        "base_de_dados[base_de_dados['Col2'] == 'X']['col5'].mean() # Filtra o dataset duas vezes e ainda chama uma fun√ß√£o. OU\n",
        "base_de_dados['col2'].groupby(base_de_dados['col5']).mean().round(1) # .round() arredonda os dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_AdYsyRBP2W"
      },
      "source": [
        "sns.boxplot(x=base_de_dados['coluna']); ##looking at column box plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FAx-Yr9zxgG"
      },
      "source": [
        "# Plota um grafico de acordo com o agrupamento; barh plota as barras na horizontal.\n",
        "base_de_dados['col2'].groupby(base_de_dados['col5']).mean().round(1).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj3WApOdzxjc"
      },
      "source": [
        "base_de_dados['colunas'].T.plot(kind='box'); # Plota em formato boxplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG03k4b06VNb"
      },
      "source": [
        "base_de_dados['col'].plot(kind='hist', edgecolor='black', bins= 10); # Plota um histograma com 10 barras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuOUd8neca7S"
      },
      "source": [
        "base_de_dados.filter(regex= 'P27') # Puxa da tabela todas as informa√ß√µes em que o Regex tiver parte ou uma palavra inteira."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H_z0JGQvg3L"
      },
      "source": [
        "base_de_dados['col3'] # Chama as informa√ß√µes da coluna selecionada."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr2yvCFKstxH"
      },
      "source": [
        "base_de_dados[['col6','col19']] # Chama as informa√ß√µes das colunas selecionadas pelo nome delas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjbODTj0uDMK"
      },
      "source": [
        "base_de_dados[base_de_dados['colunaX'] == 'M'] # Chama apenas os dados especificos da coluna selecionada."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnzZSefauDPS"
      },
      "source": [
        "base_de_dados[base_de_dados['co1'] > 4] # Chama as informa√ß√µes de acordo com o filtro."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ6B-qzLuDST"
      },
      "source": [
        "# Chama as info's das colunas de acordo com as condi√ß√µes solicitadas.\n",
        "base_de_dados[(base_de_dados['col1'] > 4) & (base_de_dados['col3'] == 'F')] #ex1\n",
        "base_de_dados.loc[base_de_dados['P3'] > 4].loc[base_de_dados['Sexo']=='F'] #ex2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ6yrS0oqUH0"
      },
      "source": [
        "# Buscando dados como SQl\n",
        "# usar f-string dentro de queries\n",
        "import pandasql as ps # !pip install pandasql\n",
        "\n",
        "filtro_idade = 30\n",
        "query = f\"\"\"select * from df where age < {filtro_idade}\"\"\"\n",
        "\n",
        "ps.sqldf(query, locals())\n",
        "\n",
        "# E se quiser a estat√≠stica descritiva por grupo?\n",
        "#df.groupby(\"Sex\")[\"Age\", \"Credit amount\", \"Duration\"].mean()\n",
        "df.groupby(\"Purpose\")[\"Age\", \"Credit amount\", \"Duration\"].mean()\n",
        "\n",
        "df.query(\" Age > 70 & Sex == 'male' \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4qi6gt7ts6"
      },
      "source": [
        "base_de_dados.loc['linha'] # Chama os valores da LINHA selecionada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4wOueW5uDUX"
      },
      "source": [
        "base_de_dados.iloc[3:,2:3] # Chama as informa√ß√µes da quarta linha pra frente da segunda coluna. √â Indexado √† posi√ß√£o dos dados no conjunto de dados."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCXgCpm58Vnb"
      },
      "source": [
        "base_de_dados.iloc[:,[1,7,6]] # Chama todas as linhas das colunas 1, 7 e 6 respectivamente."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx_Ck6SuuDY3"
      },
      "source": [
        "base_de_dados.mean() # Chama a m√©dia. axis=1 chamaria pelas m√©dias das linhas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG4B1YkZstc5"
      },
      "source": [
        "base_de_dados.T # Transp√µe os dados de colunas para os indices."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVlxHKBYEBJZ"
      },
      "source": [
        "base_de_dados[\"coluna1\"].value_counts() / len(base_de_dados) # distribui√ß√£o das categorias da coluna selecionada em percentual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aPjNgTbEMrc"
      },
      "source": [
        "base_de_dados['col1'].value_counts() # distribui√ß√£o das categorias em valores absolutos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcvXeqY5XRZD"
      },
      "source": [
        "### Testes de Hip√≥tese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jduL73IaXYzF"
      },
      "source": [
        "O que s√£o Testes de Hip√≥teses?\n",
        "\n",
        "Testes estat√≠sticos s√£o regras de decis√£o que permitem avaliar a razoabilidade das hip√≥teses feitas sobre os par√¢metros populacionais e aceit√°-las ou rejeit√°-las como provavelmente verdadeiras ou falsas tendo como base uma amostra. Em outras palavras, √© uma regra de decis√£o que ajuda a valiar hip√≥teses feitas sobre os par√¢metros populacionais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59MFQXuSXjdU"
      },
      "source": [
        "Executando o Teste de Normalidade\n",
        "\n",
        "Muito comumente declaramos uma vari√°vel sendo normal, de forma visual, baseados apenas pela curva de sino. No entanto, podemos declar√°-la normal, de forma mais robusta e formal. Podemoa aplicar testes estat√≠sticos, aceitando ou rejeitando a hip√≥tese de uma determinada distribui√ß√£o ser normal ou n√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG0-Irr1XVSc"
      },
      "source": [
        "from scipy.stats import normaltest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhgmYmOpXuPM"
      },
      "source": [
        "A fun√ß√£o 'normaltest' testa a hip√≥tese nula ùêª0 de que a amostra √© proveniente de uma distribui√ß√£o normal, atrav√©s de um teste de normalidade. √â isso que temos que rejeitar ou n√£o de acordo com a resposta de normaltest.\n",
        "Definindo a signific√¢ncia do teste ( ùõº )\n",
        "Signific√¢ncia padr√£o, com n√≠vel de confian√ßa de 95%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpNJgURDX3As"
      },
      "source": [
        "significancia = 0.05\n",
        "stat_test, valor_p = normaltest(base_dados.coluna)\n",
        "resultado = valor_p <= significancia\n",
        "print(stat_test)\n",
        "print(valor_p)\n",
        "print(f'Rejeitamos a hip√≥tese nula H0?' {resultado})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXp92TXyY_Mm"
      },
      "source": [
        "O H0 no nosso caso √© a hip√≥tese de que a amostra √© proveniente de uma distribui√ß√£o normal. A regra de rejei√ß√£o √© simples, o valor-p √© menor ou igual a signific√¢ncia alfa de 5%?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_6VX1HxZytu"
      },
      "source": [
        "Se valor-p num teste de normalidade √© de 90%, portanto, n√£o rejeitamos H0. Essa estat√≠stica se traduz em n√£o rejeitar a hip√≥tese de a vari√°vel ser normalmente distribu√≠da."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ajPFP3_2Am2"
      },
      "source": [
        "### Normaliza√ß√£o de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYM9qlnG2DRF"
      },
      "source": [
        "Obs: √Ärvores de Decis√£o n√£o precisam de nenhum tipo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6jwY3mdT4r7"
      },
      "source": [
        "# METODO ARTESANAL\n",
        "#Normalizando valores entre 400 e 900\n",
        "dados['CreditScore'] = dados['CreditScore']/1000 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu9_rRadTugU"
      },
      "source": [
        "# Normalizando a idade\n",
        "import numpy as np\n",
        "media = np.mean(dados['Age'])\n",
        "desvio = np.std(dados['Age'])\n",
        "dados['Age'] = (dados['Age'] - media)/desvio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIenYZ6DzvXB"
      },
      "source": [
        "# MinMax - tranforma os dados numa escala entre zero e 1 quando usar?  \n",
        "- quando n√£o pode ter numero negativo\n",
        "- quando n√£o sabemos a distribui√ß√£o dos dados\n",
        "- muito utlizado em Redes Neurais e processamento de imagens\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dados_norm = scaler.fit_transform(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_FltBu0IU0E"
      },
      "source": [
        "# Z-score (ESCALA PADR√ÉO) deve ser utilizado na maioria dos casos, tem dados negativos, precisa tratar outliers antes\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "sc = StandardScaler()\n",
        "rs = RobustSacaler() # RobustScaler √© menos sujeito a valores discrepantes.\n",
        "\n",
        "aux0 = sc.fit_transform(titanic[['Age', 'Fare']]) # Faz a normaliza√ß√£o dos dados\n",
        "aux1 = pd.DataFrame(aux0, columns=['Idade','Tarifa']) # Cria novas colunas com dados normalizados, trocar nome das colunas\n",
        "titanic = pd.concat([titanic, aux1], axis=1) # Coloca as novas colunas na base de dados\n",
        "titanic.drop(['Age', 'Fare'], axis=1, inplace=True) # Elimina as colunas antigas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhdJPTbbPm3P"
      },
      "source": [
        "5¬∫ **IQR:**Quando uma vari√°vel n√£o segue uma distribui√ß√£o normal, ao inv√©s de usar o m√©todo z_score \n",
        "(que assume uma distribui√ß√£o normal dos dados e confia na m√©dia e desvio padr√£o dos dados para identificar os outliers),\n",
        "aplica-se a regra do box plot (IQR interquartile range)\n",
        "\n",
        "* Ordenar os dados de forma crescente\n",
        "* Calcular Q1 e Q3\n",
        "* Encontrar IQR (Q3-Q1)\n",
        "* Definir o limite inferior Q1*1.5\n",
        "* Definir o limite superior Q3*1.5\n",
        "* Outlier √© qualquer ponto fora dos limites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpar_HdNPELA"
      },
      "source": [
        "# Ordenar os dados de forma crescente\n",
        "dataset_sorted = dataset_ohe['Fare'].sort_values()\n",
        "\n",
        "# Calcular Q1 e Q3\n",
        "q1, q3= np.percentile(dataset_sorted,[25,75])\n",
        "\n",
        "# Encontrar IQR (Q3-Q1)\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Definir o limite inferior Q1*1.5\n",
        "limite_inferior = q1 -(1.5 * iqr)\n",
        "\n",
        "# Definir o limite superior Q3*1.5\n",
        "limite_superior = q3 +(1.5 * iqr)\n",
        "\n",
        "print('q1={} | q3={} | iqr={} | limite inferior={} | limite superior={}'.format(q1,q3,iqr,limite_inferior, limite_superior))\n",
        "\n",
        "# Identificando os outliers\n",
        "dataset_ohe['is_outlier_fare'] = np.where(dataset_ohe['Fare'] < limite_inferior, 1, 0)\n",
        "dataset_ohe['is_outlier_fare'] = np.where(dataset_ohe['Fare'] > limite_superior, 1, dataset_ohe['is_outlier_fare'])\n",
        "print('{} registros marcados como outliers'.format(len(dataset_ohe[dataset_ohe['is_outlier_fare'] == 1]))) \n",
        "\n",
        "# Salva para uso futuro no pipeline de produ√ß√£o\n",
        "data = {'q1': [q1], 'q3': [q3], 'iqr': [iqr], 'limite_inferior': [limite_inferior], 'limite_superior': [limite_superior]}\n",
        "df_iqr = pd.DataFrame(data = data)\n",
        "df_iqr.to_csv('df_iqr.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRAbSrCArzLl"
      },
      "source": [
        "An√°lise de componente principal, ou PCA, √© um m√©todo de redu√ß√£o de dimensionalidade frequentemente usado para reduzir a dimensionalidade de grandes conjuntos de dados, transformando um grande conjunto de vari√°veis em um menor que ainda cont√©m a maior parte das informa√ß√µes do grande conjunto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohs0kRMlrugr"
      },
      "source": [
        "# PCA \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "data_scaled = pd.DataFrame(X_scaled, columns=data.columns)\n",
        "data_scaled.head()\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_pca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Vd3J5GIU0G"
      },
      "source": [
        "### Teste de Normalidade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tdqr2SdIU0G"
      },
      "source": [
        "# QQPlot\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "stats.probplot(dados, fit=True,   plot=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehN_xZ3NIU0I"
      },
      "source": [
        "from scipy import stats\n",
        "# Teste de Shapiro-Wilk (teste de hip√≥tese)\n",
        "stats.shapiro(dados)\n",
        "# Os dados est√£o normalmente distribu√≠dos quando 'p-value' est√° acima de 0.05."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phzWFHFv7DOQ"
      },
      "source": [
        "### Transformando dados Categ√≥ricos em num√©ricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgZzGCu8I5su"
      },
      "source": [
        "dados['smoker'] = dados['smoker'].map({'yes': 1, 'no': 0}) # Troca variaveis bin√°rias de string para 0 e 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTIZgipi7OPH"
      },
      "source": [
        "dados['job'] = dados['job'].map({'management': 0, 'blue-collar':1, 'technician': 2, 'admin.': 3, 'services': 4, 'retired': 5, 'unknown': 6}) \n",
        "dados['contact'] = dados['contact'].map({'cellular': 1, 'unknown':0, 'telephone': 2})\n",
        "dados['month'] = dados['month'].map({'jan': 0, 'feb': 1,'mar': 2, 'apr': 3, 'may': 4, 'jun': 5,'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9,'nov': 10, 'dec': 11,})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUWFkNrsJjnm"
      },
      "source": [
        "### Sele√ß√£o de Features (vari√°veis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtYBdGlvxVm_"
      },
      "source": [
        "A Feature Selection deve ser feita depois da etapa de pr√©-processamento dos dados. O objetivo √© selecionar as melhores vari√°veis como poss√≠veis vari√°veis preditoras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvXfMYY1xXVj"
      },
      "source": [
        "A etapa de feature selection ajuda a reduzir o overfitting, aumenta a acur√°cia do modelo e reduz o tempo de treinamento.\n",
        "\n",
        "Tipos de Algoritmos e M√©todos\n",
        "\n",
        "Filter Methods : M√©todos de sele√ß√£o que utiliza medidas estat√≠sticas para atribuir um score para cada feature. As features s√£o classificadas pelo score para serem mantidas ou removidas do modelo. Normalmente se usam testes univariados que consideram a independ√™ncia da feature com a vari√°vel alvo. Exemplo: chi squared, scores com coeficiente de correla√ß√£o.\n",
        "Wrapper Methods : M√©todos de sele√ß√£o que selecionam um conjunto de features, onde diferentes combina√ß√µes s√£o preparadas, avaliadas e comparadas. Um modelo preditivo √© usado para avaliar a combina√ß√£o de features a atribuir um score baseado em uma acur√°cia de modelo. Exemplo: algoritmo RFE\n",
        "Embedded Methods : M√©todos Embedded aprendem quais feature melhor contribuiem para a acur√°cia do modelo no momento de constru√ß√£o do modelo. Exemplo: m√©todos de penaliza√ß√£o, algoritmos Lasso, Elastic NEt e Ridge Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quUR4DcFxagQ"
      },
      "source": [
        "Qual M√©todo utilizar?\n",
        "\n",
        "Tente usar o RFE caso tenha recursos computacionais para isso.\n",
        "Se estiver trabalhando com Classifica√ß√£o e as features forem num√©ricas utilize f_classif ou mutual_info_classif.\n",
        "Se estiver trabalhando com Regress√£o e as features forem num√©ricas utilize f_regression ou mutual_info_regression.\n",
        "Caso esteja trabalhando com features categ√≥ricas utilize chi2\n",
        "Automatize essa etapa com Pipelines para evitar erros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S90ITfVbxpoT"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "f_classif = SelectKBest(score_func=f_classif, k=4)\n",
        "fit = f_classif.fit(X,y)\n",
        "features = fit.transform(X)\n",
        "cols = fit.get_support(indices=True)\n",
        "dados.iloc[:,cols].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4AOeOoiIzuG"
      },
      "source": [
        "import numpy as np # Verificando a correla√ß√£o das vari√°veis com a target\n",
        "correlacao = np.corrcoef(X, y)\n",
        "correlacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-dSUYvw1mtC"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X = dados.drop('Target', axis = 1)\n",
        "y = dados['Target']\n",
        "\n",
        "modelo_base = RandomForestClassifier(max_depth = 3) \n",
        "modelo_base.fit(X, y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiguOHw-Jr9G"
      },
      "source": [
        "modelo_base.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgrt8tf0-oMz"
      },
      "source": [
        "variaveis = pd.DataFrame()\n",
        "variaveis['variavel'] = X.columns\n",
        "variaveis['import√¢ncia'] = modelo_base.feature_importances_\n",
        "variaveis.sort_values(by = 'import√¢ncia', ascending = True, inplace = True)\n",
        "variaveis.set_index('variavel', inplace = True)\n",
        "variaveis.plot(kind='barh', figsize=(8, 5));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huqq71iw7fKf"
      },
      "source": [
        "### Dummyficando as colunas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvx1GucH7ihu"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dados = pd.get_dummies(dados, columns = ['job', 'marital', 'education', 'contact', 'month', 'poutcome'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1WCUuHqA8HL"
      },
      "source": [
        "variaveis_cat = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService'] \n",
        "\n",
        "treino = pd.get_dummies(treino, columns = variaveis_cat, drop_first = True)\n",
        "\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HqiD7t273EP"
      },
      "source": [
        "# Transformando dataset em Matriz para Machine Learning\n",
        "X = dados.iloc[:,0:6].values # todos os valores de todas as colunas da 0 at√© a 5\n",
        "y = dados.iloc[:,6].values # a coluna da classe. 'target'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DQDTtTfpEzv"
      },
      "source": [
        "### C√≥digos para manipula√ß√£o (binning) e explora√ß√£o de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKVJD7C5IU0N"
      },
      "source": [
        "dados['colunaX'] = dados['colunaX'].map({'antigo':'novo', 'antigo': 1, 458: 'novo'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uWJoh_sstrW"
      },
      "source": [
        "base_de_dados.sample(3) # Mostra uma amostra aleat√≥ria de tr√™s linhas ao inv√©s de usar head ou tale."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwmfVPVLIU0N"
      },
      "source": [
        "#Somando todos os valores presentes na Series por 2\n",
        ">>> s.add(2)\n",
        "#Subtraindo 2 de todos os valores\n",
        ">>> s.sub(2)\n",
        "#Multiplicando todos os valores por 2\n",
        ">>> s.mul(2)\n",
        "titanic['fulanos'] = titanic['SibSp'].mul(100)\n",
        "#Dividindo valores por 2\n",
        ">>> s.div(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JficVtz8stlu"
      },
      "source": [
        "base_de_dados.info() # Mostra informa√ß√µes sobre o dados faltantes e do formato dos dados das colunas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mDhpv09XlJY"
      },
      "source": [
        ".unstack().T # Cria duas colunas selecionadas em uma 'mini base de dados'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1d3dK_Y4PaR"
      },
      "source": [
        "dados2 = base_de-dados[['Fare','Sex_male', 'Titulo_Mr']] # Seleciona algumas colunas apenas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo_P8Y55stop"
      },
      "source": [
        "base_de_dados.shape # Mostra a qtde de linhas e colunas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5NZY9-Ks_u"
      },
      "source": [
        "base_de_dados[\"coluna\"].value_counts() # Conta os valores da coluna selecionada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewOynVbn6VQI"
      },
      "source": [
        "base_de_dados.concat(['basedados1','basedados2']) #Concatena dois conjuntos de dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MWiaheR_2h5"
      },
      "source": [
        "pd.concat([dados, dados2], axis=1) # JUNTA DUAS TABELAS EM QUE AS COLUNAS FICAM LADO A LADO."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfUV7hKhEweS"
      },
      "source": [
        "base_de_dados['novaColuna'] = variavelNova # Adiciona no conjunto uma nova coluna com os dados novos."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uDjqsom2dIK"
      },
      "source": [
        "# Busca das informa√ß√µes da coluna selecionada\n",
        "agrupado = base_de_dados.groupby(['coluna']).size()\n",
        "agrupado\n",
        "\n",
        "# padronizando uma informa√ß√£o\n",
        "base_de_dados.loc[base_de_dados['Genero'] ==  'M', 'Genero'] = \"Masculino\"\n",
        "\n",
        "# padronizando varias informa√ß√µes\n",
        "base_de_dados.loc[base_de_dados['Genero'].isin( ['Fem','F']), 'Genero'] = \"Feminino\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFK7vHgEIU0Q"
      },
      "source": [
        "#Pr√©-processamento inicial das vari√°veis\n",
        "\n",
        "dic = {'A11': 'negativo', 'A12': '[0-200)', 'A13': '200+', 'A14': 'sem conta'}\n",
        "dados['conta'] = dados['conta'].map(dic)\n",
        "\n",
        "\n",
        "dic = {'A30': 'primeira vez', 'A31': 'creditos quitados', 'A32': 'pagamento em dia', \n",
        "       'A33': 'j√° atrasou pagamentos', 'A34': 'conta cr√≠tica'}\n",
        "dados['historico'] = dados['historico'].map(dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZzRc36nUIoK"
      },
      "source": [
        "conjunto = ['dado1', 'dado2', 'dado3', '...', 'dadox']\n",
        "colunas = ['P1','P2','P3','P4']\n",
        "nova_base = pd.DataFrame(nova_base, index=conjunto, columns=colunas) # Cria um novo conjunto de dados indexado pelo conjunto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8J-whLP3jVW"
      },
      "source": [
        "base_de_dados['coluna1'] = base_de_dados['coluna1'].astype('float64') # Convertendo coluna string em float"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-lpd9RWQ_xE"
      },
      "source": [
        "base_de_dados = base_de_dados.drop(0) # Exclui a linha selecionada nesse caso, a primeira"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm-wc0_tcElO"
      },
      "source": [
        "base_de_dados.drop(base_de_dados.loc[base_de_dados['nome_coluna'] < 1000].index, inplace=True) # Seleciona e exclui linhas selecionadas com condi√ß√µes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB6d5AbKQ_kt"
      },
      "source": [
        "# excluindo as colunas das variaveis selecionadas\n",
        "dados.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evI0nv23KtFE"
      },
      "source": [
        "base_de_dados.to_csv('nome-da-base.csv', sep= ',') # Salva a base de dados tratada em csv."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pujO-uvGHrx2"
      },
      "source": [
        "from IPython.display import Image # Colocando imagem no notebook\n",
        "Image('Treinamento.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwNlj62XV4l9"
      },
      "source": [
        "### Dados nulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk6MbpG_yRiw"
      },
      "source": [
        "dataset.duplicated().sum() # conta linhas duplicadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVERbfRgyRdq"
      },
      "source": [
        "base_de_dados[base_de_dados.duplicated()] # Pesquisando dados duplicados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEgdt8A_yRap"
      },
      "source": [
        "base_de_dados.drop_duplicates(keep='last') # apagando dados duplicados, mantendo o √∫ltimo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llb_hCCYyZt5"
      },
      "source": [
        "dataset.isnull().sum() # Conta dados nulos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ukn58VGyBfB"
      },
      "source": [
        "base_de_dados.isnull().sum().sort_values(ascending=False) # Buscar por dados NaN (faltantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULOV8mqBDDUb"
      },
      "source": [
        "import missingno as msno # Se houver dados faltantes, verificando aonde est√£o\n",
        "msno.matrix(dados, figsize= (10,6), color= (0, 0.1, 0.25), sparkline=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJCy0BMbIU0U"
      },
      "source": [
        "# substituindo campos vazios pela media\n",
        "nulos = ['Resource Allocation','Mental Fatigue Score','Burn Rate']\n",
        "dados[nulos] = dados[nulos].replace({np.nan: dados['Resource Allocation'].mean(), \n",
        "                                     np.nan: dados['Burn Rate'].mean(), \n",
        "                                     np.nan: dados['Mental Fatigue Score'].mean()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVijHbDslKdV"
      },
      "source": [
        "base_de_dados.isnull().sum()\n",
        "# substituindo campos vazios pela mediana\n",
        "base_de_dados['coluna'].describe() # c√≥digo que mostra algumas informa√ß√µes estat√≠sticas, entre elas a mediana\n",
        "mediana = sts.median(base_de_dados['coluna']) # cri√ß√£o da vari√°vel mediana, que ser√° preenchida nos campos vazios\n",
        "base_de_dados['coluna'].fillna(mediana, inplace=True)\n",
        "base_de_dados.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgZR3pPJ0jZk"
      },
      "source": [
        "# localizando a moda da coluna\n",
        "agrupado = base_de_dados.groupby(['coluna']).size()\n",
        "agrupado\n",
        "# substituindo campos vazios pela moda\n",
        "base_de_dados['coluna'].fillna('Moda', inplace=True)\n",
        "#Verificamos se NAN n√£o existem mais\n",
        "base_de_dados['Salario'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfDRoaVO3y2B"
      },
      "source": [
        "Binning √© a jun√ß√£o das linhas mais raras no seu dataset. Com isso, reduz as complexidades das caracter√≠sticas. Melhorando a performance do modelo. Pode ser usado em vari√°veis categ√≥ricas e num√©ricas e pode utilizar a categoria outros para baixa cardinalidade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAuLXc-zoB-L",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "print(base_de_dados['coluna'].value_counts()) # value_counts() conta as qtes por nome\n",
        "plt.figure()\n",
        "grafico = sns.countplot('coluna', data=base_de_dados) # countplot √© tipo value_counts dos graficos\n",
        "grafico.tick_params(axis='x', rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbKA5vg0xcT"
      },
      "source": [
        "# dados categoricos necessitam ser substituidos pela moda:\n",
        "agrupado = base_de_dados.groupby(['Estado']).size() # nesse exemplo o valor √© RS\n",
        "# no exemplo, nosso cliente atua apenas na regi√£o sul e portanto existem dados que precisam ser tratados\n",
        "base_de_dados.loc[base_de_dados['Estado'].isin( ['RP','SP','TD']), 'Estado'] = \"RS\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_46WT-2zVMG"
      },
      "source": [
        "base_de_dados['smoker'] = base_de_dados['smoker'].map({'yes': 1, 'no': 0}) # Troca variaveis bin√°rias de string para 0 e 1. Pode utilizar para palavras tambem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpqhNSDyxcf"
      },
      "source": [
        "base_de_dados['coluna'] = base_de_dados['coluna'].str.replace('R$','') # substitui cifr√£o por espa√ßo nos dados da coluna selecionada\n",
        "base_de_dados['coluna'] = base_de_dados['coluna'].str.replace(',','') # preco precisa ser com ponto\n",
        "base_de_dados['coluna'] = base_de_dados['coluna'].astype(np.float32, copy=False) #convers√£o p/float"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2K-fAD011ZK"
      },
      "source": [
        "# discretiza√ß√£o da idade (escolha arbitraria dos cortes)\n",
        "cortes = [0, 24, 30, 40, 100] # faixas de idade\n",
        "nomes = ['[18,24]', '[25,30]', '[31,40]', '[41,50]']\n",
        "\n",
        "# comando cut vai cortar o banco de dados nas faixas acima e colocar nas devidas novas colunas (nomes)\n",
        "dados['idade'] = pd.cut(dados[\"('P1', 'age')\"], bins = cortes, labels = nomes) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40MH1w-S8hD"
      },
      "source": [
        "# criando vari√°veis mais convenientes\n",
        "# os valores do lado esquerdo sao os que est√£o na coluna original e a direita sao os novos valores\n",
        "\n",
        "# coluna empresas\n",
        "tammap = { 'de 1 a 100': 'Pequena',\n",
        "           'de 101 a 1000': 'M√©dia',\n",
        "           'Acima de 1000': 'Grande'}\n",
        " \n",
        "# coluna salarios\n",
        "salamap = {    'Menos de R$ 1.000/m√™s': 1000,\n",
        "      'de R$ 1.001/m√™s a R$ 2.000/m√™s': 1500, \n",
        "       'de R$ 2.001/m√™s a R$ 3000/m√™s': 2500,\n",
        "      'de R$ 3.001/m√™s a R$ 4.000/m√™s': 3500,\n",
        "               'Acima de R$ 5.000/m√™s': 5000}\n",
        "\n",
        "# criando novas colunas com as informa√ß√µes alteradas: \n",
        "dados['salario'] = dados[\"('P16', 'salary_range')\"].map(salamap)  \n",
        "dados['tamanho_da_empresa'] = dados[\"('P12', 'workers_number')\"].map(tammap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFO3W4ylMxNH"
      },
      "source": [
        "#Exemplo : temos o endere√ßo '917, 1st St, Dallas, TX 75001' na coluna Adress de um banco de dados:\n",
        "# Usando o apply()\n",
        "def get_city(adress):\n",
        "  return address.split(,)[1]\n",
        "\n",
        "def get_state(address):\n",
        "  return address.split(,)[2].split(' ')[1]\n",
        "  \n",
        "base_de_dados['Cidade'] = base_de_dados['Address'].apply(lambda x: f'{get_city(x)} ({get_state(x)})') \n",
        "# fun√ß√£o que retira informa√ß√£o entre as v√≠rgulas e salva em uma nova coluna.\n",
        "# Vai retornar na coluna Cidade apenas a palavra 'Dallas (TX)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2AsMg9HEGkP"
      },
      "source": [
        "# Agrupando diversos valores numa categoria como OUTROS\n",
        "nome = pd.read_csv('train.csv', usecols=['Name'])\n",
        "titulacao = []\n",
        "for i in range(nome.shape[0]):\n",
        "    titulacao.append(nome.iloc[i,0].split(', ')[1].split('. ')[0])\n",
        "\n",
        "tt = []\n",
        "for i in range(nome.shape[0]):\n",
        "    if titulacao[i] in ['Mr','Miss','Mrs','Master']:\n",
        "        tt.append(titulacao[i])\n",
        "    else:\n",
        "        tt.append('Outros')\n",
        "titanic['Titulo'] = tt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdXCtgh50xhr"
      },
      "source": [
        "def auxiliar(x):\n",
        "    if x == 0:\n",
        "        return 'Zerada'\n",
        "    elif x < 100000:\n",
        "        return 'At√© 100k'\n",
        "    elif x < 150000:\n",
        "        return '100k - 150k'\n",
        "    else:\n",
        "        return '150k+'\n",
        "\n",
        "dados['Balance'] = dados['Balance'].apply(auxiliar)\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hex-5md0xUT"
      },
      "source": [
        "# AGRUPAMENTO DE CATEGORIAS\n",
        "def auxiliar(x):\n",
        "    if x <= 3:\n",
        "        return '0-3'\n",
        "    elif x <= 6:\n",
        "        return '4-6'\n",
        "    else:\n",
        "        return '7-10'\n",
        "\n",
        "dados['Tenure'] = dados['Tenure'].apply(auxiliar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PJPY_D0oB-L",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "#A sugest√£o √©, agrupar valores muito pequenos deixando os dados mais compactos e indo direto nas infos que importam:\n",
        "tabela_outros = dataset['coluna'].value_counts()  # agrupando tudo novamente so que numa variavel\n",
        "colunas_agrupar = [] # lista vazia\n",
        "\n",
        "for i in tabela_outros.index:\n",
        "    if tabela_outros[i] < x:     # x √© a qtde deseja agrupar\n",
        "        colunas_agrupar.append(i)\n",
        "print(colunas_agrupar) # para ler as colunas que foram para a variavel\n",
        "\n",
        "#Agora, subtituir esses nomes com poucos valores por um s√≥, agrupando-os:\n",
        "for i in colunas_agrupar:\n",
        "    base_de_dados.loc[base_de_dados['coluna']== i, 'coluna']== 'OUTROS'\n",
        "\n",
        "# Reimprimindo os dados dessa coluna para ver se ficou melhor:\n",
        "print(base_de_dados['coluna'].value_counts())\n",
        "\n",
        "plt.figure()\n",
        "grafico = sns.countplot('coluna', data=base_de_dados) # countplot √© um 'value_counts' dos graficos\n",
        "grafico.tick_params(axis='x', rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkwKyyOum89h"
      },
      "source": [
        "### Outliers Num√©ricos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O18gbSfx2-Xw"
      },
      "source": [
        "Para tratar outliers dos dados n√£o existe uma regra universal, por√©m o setup que ajusta bem no processo de ML √© utilizar 2 desvios padr√£o:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRNLoHWdgLX"
      },
      "source": [
        "# localizando dados outliers basicos como idade negativa etc\n",
        "base_de_dados.loc[ (base_de_dados['coluna'] < 0 'ou outro parametro') | (base_de_dados['Idade'] >= 'parametro') ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbrLPAafdgLX"
      },
      "source": [
        "# substituindo os outliers pela mediana da variavel\n",
        "mediana = sts.median(dataset['coluna'])\n",
        "base_de_dados.loc[ (base_de_dados['coluna'] < 0 'ou outro parametro') | (base_de_dados['Idade'] >= 'parametro') ] = mediana"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdedTojGdgLX",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "# Verificar se tem algum valor fora do crit√©rio (de dois desvios):\n",
        "base_de_dados.loc[base_de_dados['coluna'] >=  2 * desv ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx8VlgALdgLX",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "# Se houver: calculando o desvio padr√£o dos valores de uma coluna:\n",
        "desvio = sts.stdev(dataset['coluna'])\n",
        "# Realizar a subst. de outliers pela mediana\n",
        "base_de_dados.loc[base_de_dados['coluna'] >=  2 * desvio, 'coluna'] = mediana"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drZ0zu7jdgLY",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "#visualizar \n",
        "base_de_dados.loc[(base_de_dados['Idade'] <  0 )  | ( base_de_dados['Idade'] >  120) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR3mFtHour_h"
      },
      "source": [
        "# TRATANEDO OUTLIERS POR QUANTIS\n",
        "dados['Fare'].plot(kind = 'box');\n",
        "top = dados['Fare'].quantile(0.90)\n",
        "dados.loc[dados['Fare'] > top, 'Fare'] = top\n",
        "dados['Fare'].plot(kind = 'box');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWx7KJtdgLd"
      },
      "source": [
        "### Convers√µes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNImYZTpdgLe"
      },
      "source": [
        "#Convert DAYS to YEARS\n",
        "cust_data['EMP_YEARS'] = cust_data.DAYS_EMPLOYED/365\n",
        "cust_data['AGE'] = cust_data.DAYS_BIRTH/365\n",
        "cust_data.drop([\"DAYS_BIRTH\",\"DAYS_EMPLOYED\"],axis = 1,inplace = True)\n",
        "cust_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzGNaLLnIU0a"
      },
      "source": [
        "# Convers√£o dos atributos que est√£o no formato string para formato de data: ANO-M√äS\n",
        "dateparse = lambda dates: datetime.strptime(dates, '%Y-%m')\n",
        "dataset = pd.read_csv('tua_planilha.csv', parse_dates = ['coluna_data'],\n",
        "                   index_col = 'coluna_data', date_parser = dateparse)\n",
        "dataset #para verificar se mudou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkj5gaDcIU0a"
      },
      "source": [
        "# fun√ß√£o contador total de dias a partir de uma coluna de data da base\n",
        "def create_days_count(data):\n",
        "    return (current_date - data[\"Date of Joining\"])\n",
        "\n",
        "# Contando os dias\n",
        "df = dados\n",
        "current_date = pd.to_datetime('today')  \n",
        "# Adicionando o contador de dias na base de dados\n",
        "df[\"days_count\"] = df.apply(create_days_count, axis=1).dt.days"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAWe96jmPK9Y"
      },
      "source": [
        "# Convers√£o de datas\n",
        "dados['dtIncioObra'] = pd.to_datetime(dados5['dtInicio'], dayfirst=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ue7KdiNC55"
      },
      "source": [
        "from datetime import datetime\n",
        "# Convers√£o dos atributos que est√£o no formato string para formato de data: ANO-M√äS\n",
        "dateparse = lambda dates: datetime.strptime(dates, '%Y-%m')\n",
        "dataset = pd.read_csv('tua_planilha.csv', parse_dates = ['coluna_data'],\n",
        "                   index_col = 'coluna_data', date_parser = dateparse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxZU3I3gM3gX"
      },
      "source": [
        "base_de_Dados['colunadadata'] = pd.to_datetime(base_de_Dados['colunadadata']) #Converte a data da coluna que estiver em outro formato"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRJO0CXDNwyH"
      },
      "source": [
        "base_de_Dados['hora'] = base_de_Dados['colunadadata'].dt.hour # cria uma coluna mostrando a hora da coluna original\n",
        "base_de_Dados['minuto'] = base_de_Dados['colunadadata'].dt.minute # cria uma coluna mostrando os minutos da coluna original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUfia-09IU0b"
      },
      "source": [
        "### Valida√ß√£o Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNVh68QhIU0b"
      },
      "source": [
        "# Hold-out\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Vr-QigIU0b"
      },
      "source": [
        "# K-fold estratificado\n",
        "from sklearn.model_selection import cross_validate # para cruzar valida√ß√µes dos modelos\n",
        "from sklearn.model_selection import StratifiedKFold # estratificando amostra do Kfold\n",
        "validacao = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cALTHXaMIU0c"
      },
      "source": [
        "### Modelos de ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMxbwrCIU0c"
      },
      "source": [
        "# Alguns modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier \n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg59BIahIU0c"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QheznAiMIU0c"
      },
      "source": [
        "# Utiliza√ß√£o do algoritmo ExtraTreesClassifier para identificar as variaveis mais importantes \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "forest = ExtraTreesClassifier()\n",
        "forest.fit(X_treinamento, y_treinamento)\n",
        "importancias = forest.feature_importances_\n",
        "importancias #Ele responde com o valor que cada coluna tem de importancia. \n",
        "# Note que n√£o √© em ordem do maior para o menor mas sim na ordem que as colunas est√£o dispostas na nossa base de dados."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzu7I_u4IU0d"
      },
      "source": [
        "#gera√ß√£o da matriz de confus√£o e c√°lculo da taxa de acerto e erro:\n",
        "confusao = confusion_matrix(y_teste, previsoes)\n",
        "confusao\n",
        "# MATRIZ DE CONFUS√ÉO\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"Matriz de Confus√£o : \\n\" + str(confusion_matrix(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdr6Pqn8IU0d"
      },
      "source": [
        "### Dados desbalanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJSs5FEIU0d"
      },
      "source": [
        "# Verificando se a classe est√° desbalanceada\n",
        "y.value_counts().plot.pie(autopct='%.2f');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fIzOu0hIU0d"
      },
      "source": [
        "#### Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbHebRj5IU0d"
      },
      "source": [
        "Simplesmente vai jogar fora grande parte dos dados, deixando as classes balanceadas.\n",
        "Ex: Aqui, temos 500 dados 0 para 70k 1, o undersampling vai descartar todos os dados at√© chegar em 500/500 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCrpwuAbIU0e"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy= 1) # para numeros\n",
        "#rus = RandomUnderSampler(sampling_strategy='not minority') # para strings\n",
        "X_us, y_us = rus.fit_resample(X, y)\n",
        "\n",
        "# Conferindo o balan√ßo\n",
        "ax = y_us.value_counts().plot.pie(autopct='%2.f')\n",
        "_ = ax.set_title('Under Sampling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl1jEGQNIU0e"
      },
      "source": [
        "ou"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycvXsmdlIU0e"
      },
      "source": [
        "def UnderSampling(dados, under = 1):\n",
        "    classe0 = dados[dados['Class'] == 0]\n",
        "    classe1 = dados[dados['Class'] == 1]\n",
        "\n",
        "    amostra0 = classe0.sample(under * classe1.shape[0])\n",
        "    under = pd.concat([amostra0, classe1])\n",
        "\n",
        "    return under"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jothf-6DIU0e"
      },
      "source": [
        "# Verificando o trade-off em v√°rios tamanhos de dados\n",
        "under1 = UnderSampling(dados, 1) # Amostra 1 pra 1.\n",
        "under2 = UnderSampling(dados, 2) # Amostra 2 pra 1.\n",
        "under5 = UnderSampling(dados, 5) # Amostra 5 pra 1.\n",
        "under10 = UnderSampling(dados, 10) # Amostra 10 pra 1.\n",
        "under25 = UnderSampling(dados, 25) # Amostra 25 pra 1.\n",
        "under40 = UnderSampling(dados, 40) # Amostra 40 pra 1. Esse pode ser o melhor.\n",
        "underX = UnderSampling(dados, X) # Amostra X pra 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnijrUlZIU0f"
      },
      "source": [
        "Agora, modelando novamente, utilizando Pycaret e o novo banco de dados undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evMoOpw2IU0f"
      },
      "source": [
        "modelagem = setup(data= under1,\n",
        "                  target= 'Class',\n",
        "                  test_data= teste,\n",
        "                  normalize= True)\n",
        "\n",
        "# Selecionando alguns bons modelos para problemas de fraude\n",
        "modelos = ['et', 'rf', 'lightgbm', 'dt', 'lr', 'svm']\n",
        "\n",
        "# Modelando\n",
        "modelo = compare_models(include= modelos, sort= 'F1')\n",
        "pred = predict_model(modelo)\n",
        "\n",
        "# Utilizar outros 'undersamplings' para detectar o melhor modelo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gho7Q8uwIU0f"
      },
      "source": [
        "#### Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4C7q2kLIU0f"
      },
      "source": [
        "Replica a classe minorit√°ria at√© balancear os dados. Simplesmente REPETE os dados mesmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHduu9vGIU0g"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#ros = RandomOverSampler(sampling_strategy=1) # para float\n",
        "ros = RandomOverSampler(sampling_strategy='not majority') # para string\n",
        "X_os, y_os = ros.fit_resample(X, y)\n",
        "\n",
        "# plotando gr√°fico\n",
        "ax = y_os.value_counts().plot.pie(autopct='%.2f')\n",
        "_ = ax.set_title('Over Sampling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZe2SQuVIU0g"
      },
      "source": [
        "ou"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhUzpVMzIU0g"
      },
      "source": [
        "def UnderOverSampling(dados, , under =1, over = 1):\n",
        "    classe0 = dados[dados['Class'] == 0]\n",
        "    classe1 = dados[dados['Class'] == 1]\n",
        "\n",
        "    amostra0 = classe0.sample(under * classe1.shape[0])\n",
        "    amostra1 = pd.concat([classe1] * over, ignore_index= True)\n",
        "    tudo = pd.concat([amostra0, amostra1])\n",
        "\n",
        "    return tudo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBHGLYcqIU0g"
      },
      "source": [
        "# Verificando o trade-off em v√°rios tamanhos de dados\n",
        "underover1 = UnderOverSampling(dados, under= 20, over= 4)\n",
        "underover2 = UnderOverSampling(dados, under= 20, over= 8)\n",
        "underover3 = UnderOverSampling(dados, under= 20, over= 12)\n",
        "underover4 = UnderOverSampling(dados, under= 20, over= 16)\n",
        "underover5 = UnderOverSampling(dados, under= 20, over= 20) # Melhor modelo neste problema. Recall 1 prec. 0.79\n",
        "underoverX = UnderOverSampling(dados, under= 20, over= Xvezes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rnvs-oQIU0g"
      },
      "source": [
        "# modelando\n",
        "modelagem = setup(data= underover1,\n",
        "                  target= 'Class',\n",
        "                  test_data= teste,\n",
        "                  normalize= True)\n",
        "\n",
        "# Selecionando alguns bons modelos para problemas de fraude\n",
        "modelos = ['et', 'rf', 'lightgbm', 'dt', 'lr', 'svm']\n",
        "\n",
        "# Modelando\n",
        "modelo = compare_models(include= modelos, sort= 'F1')\n",
        "pred = predict_model(modelo)\n",
        "\n",
        "# Utilizar outros 'undersamplings' para detectar o melhor modelo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI9gOs7VIU0h"
      },
      "source": [
        "#### Outras t√©cnicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVNYWao8IU0h"
      },
      "source": [
        "Considerar t√©cnicas mais robustas para esse prop√≥sito:\n",
        "\n",
        "* **Near Miss** para undersamplig\n",
        "* **SMOTE** para oversampling -- tem no pycaret\n",
        "\n",
        "\n",
        "- Ler as bibliotecas imblearn e pycaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBf1Lut3IU0h"
      },
      "source": [
        "### Salvando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiK5SFUXIU0h"
      },
      "source": [
        "#Comando de Salvamento da M√°quina Preditiva\n",
        "import pickle \n",
        "pickle_out = open(\"maquina_preditiva.pkl\", mode = \"wb\") \n",
        "pickle.dump(maquina, pickle_out) \n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOjpQNNQIU0i"
      },
      "source": [
        ""
      ]
    }
  ]
}