{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codigos-python.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Vlm5X2lL_Za",
        "txokNsEBlUjO",
        "NcvXeqY5XRZD",
        "9ajPFP3_2Am2",
        "u9Vd3J5GIU0G",
        "phzWFHFv7DOQ",
        "qUWFkNrsJjnm",
        "Huqq71iw7fKf",
        "2DQDTtTfpEzv",
        "wwNlj62XV4l9",
        "KkwKyyOum89h",
        "iEWx7KJtdgLd",
        "bUfia-09IU0b",
        "cALTHXaMIU0c",
        "vg59BIahIU0c",
        "Wdr6Pqn8IU0d",
        "hBf1Lut3IU0h"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "af573f283834de0d94267a2f349eb6a57bfc80fc16df6f4176b3eb1c7a5367fc"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaovictordds/joaovictordds/blob/Deploy/codigos_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Vlm5X2lL_Za"
      },
      "source": [
        "### Carregando dados no notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuPo8ODhL9Ee"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1qwUqHRwNTz"
      },
      "source": [
        "pd.set_option('display.max_columns', None) # Codigo para mostrar todas as colunas do dataset.\n",
        "\n",
        "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "caminho = 'nome_arquivo.csv'\n",
        "\n",
        "dados = pd.read_csv(url, delimiter = ' ', header = None)  # Sem cabeçalho\n",
        "dados = pd.read_csv(caminho, sep=';', encoding='ISO-8859-1', low_memory=False)\n",
        "# Especificando o 'type' da coluna pelo nome da coluna ao imputar a base (para bases de poucas colunas)\n",
        "base_de_dados = pd.read_csv(caminho, dtypes= {'nome_coluna':str, 'nome_coluna':int, 'nome_coluna':str, 'nome_coluna':float})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ1rhZUaIUzy"
      },
      "source": [
        "# renomeando colunas\n",
        "nomes = ['conta', 'duração', 'historico', 'motivo', 'quantia', \n",
        "         'poupança', 'emprego', 'taxa', 'status', 'garantia', \n",
        "         'residencia', 'propriedades', 'idade', 'financiamentos', 'moradia', \n",
        "         'creditos', 'trabalho', 'dependentes', 'telefone', 'estrangeiro', 'pagador']\n",
        "         \n",
        "dados.columns = nomes\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txokNsEBlUjO"
      },
      "source": [
        "### Explorando Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLUN8INuIUzz"
      },
      "source": [
        "import dtale \n",
        "import dtale.app as detalhe\n",
        "\n",
        "detalhe.USE_NGROK = True\n",
        "detalhe.show(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6olhmnpYY6t"
      },
      "source": [
        "import pandas_profiling\n",
        "dados.profile_report() # Mostra uma relação mais detalhada que a .describe()/.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BITDgxNlIUz0"
      },
      "source": [
        "import dataprep\n",
        "from dataprep.eda import *\n",
        "create_report(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJHJtVhBrHJj"
      },
      "source": [
        "import sweetviz as sv\n",
        "eda = sv.analyze(source = dados, target_feat = 'Exited')\n",
        "eda.show_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhsbADN2IUz1"
      },
      "source": [
        "from autoplotter import run_app\n",
        "#run_app(dados, mode = 'inline')\n",
        "run_app(dados, mode = 'external')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJhP8R1YcaU"
      },
      "source": [
        "from google.colab.data_table import DataTable\n",
        "DataTable(dados.T.round(2)) # mostra os dados em forma de tabela (Aqui usei .T para transpor e round pra 2 casas decimais)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQM2VP9nLfkV"
      },
      "source": [
        "base_de_dados.describe() # Mostra uma descrição estatistica das colunas numéricas que encontrar.\n",
        "df.describe(include=['object']) # Mostra a descrição das categóricas também"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pwxRsl6rP3b"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vcxYqACIUz2"
      },
      "source": [
        "# Buscando valores\n",
        "df['new_col'].where(df['new_col'] > 0 , 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5mtHaEcIUz3"
      },
      "source": [
        "# Está em\n",
        "years = ['2010','2014','2017']\n",
        "df[df.year.isin(years)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHodECB3L4Ce"
      },
      "source": [
        "sns.pairplot(base_de_dados[[\"coluna1\", \"coluna2\", \"coluna3\", \"colunaX\"]], diag_kind=\"kde\"); # Vendo a correlação das variaveis selecionadas entre elas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbSBayDjA_4m"
      },
      "source": [
        "base_de_dados[\"Cilindros\"].value_counts() / len(dados) # Distribuição da categoria"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CDBRnZoprsb"
      },
      "source": [
        "sns.countplot(dataset['aprovacao_emprestimo']); # conta as info da variavel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rMLVdBZlOw1"
      },
      "source": [
        "# Resumo grafico boxplot\n",
        "sns.boxplot(base_de_dados['coluna']).set_title('titulo_col')\n",
        "# vertical\n",
        "dataset.boxplot(column='emprestimo', vert=False );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "danHjl5tlbO3"
      },
      "source": [
        "# Resumo grafico histograma\n",
        "sns.histplot(base_de_dados['coluna']).set_title('titulo_col')\n",
        "# linha média\n",
        "sns.histplot(dataset['emprestimo'], bins=50, kde=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf9geUBlqMWd"
      },
      "source": [
        "# Vários graficos\n",
        "sns.pairplot(dataset, hue='aprovacao_emprestimo'); # kind='reg' é a reta de regressão"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6aSABfqtyRG"
      },
      "source": [
        "# Grafico Pizza\n",
        "dados['Balance'].value_counts().plot(kind ='pie')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQjSTBsGqDcc"
      },
      "source": [
        "# Grafico de dispersao\n",
        "sns.scatterplot(data=dataset, x=\"emprestimo\", y=\"renda\");\n",
        "#sns.scatterplot(data=dataset, x=\"emprestimo\", y=\"renda\", hue='aprovacao_emprestimo');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsJNBhjplecg"
      },
      "source": [
        "#exibindo dados de forma gráfica para analisar correlações entre os dados\n",
        "sns.heatmap(base_de_dados.corr(), annot=True, cmap='Greens')\n",
        "# print(dataset.corr()) # aqui mostra a mesma correlação só que em formato tabela."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jyOvUuPJ3kM"
      },
      "source": [
        "# Correlação em formato tabela\n",
        "dados.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI2z5YhkBjNa"
      },
      "source": [
        "##pairplots to get an intuition of potential correlations\n",
        "sns.pairplot(base_de_dados[[\"MPG\", \"Cilindros\", \"Autonomia\", \"Peso\", \"cv\"]], diag_kind=\"kde\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ1vLPrvzxV0"
      },
      "source": [
        "base_de_dados.sort_values(by='COl1', ascending=False) # Ordena o dataset pela coluna selecionada e do maior para o menor."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTIaRC3-zxbE"
      },
      "source": [
        "base_de_dados.sort_values(by=['COl1','col4'], ascending=False) # Ordena o dataset pelas colunas selecionadas e do maior pro menor depois."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37MjQU1Kzxd4"
      },
      "source": [
        "base_de_dados[base_de_dados['Col2'] == 'X']['col5'].mean() # Filtra o dataset duas vezes e ainda chama uma função. OU\n",
        "base_de_dados['col2'].groupby(base_de_dados['col5']).mean().round(1) # .round() arredonda os dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_AdYsyRBP2W"
      },
      "source": [
        "sns.boxplot(x=base_de_dados['coluna']); ##looking at column box plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FAx-Yr9zxgG"
      },
      "source": [
        "# Plota um grafico de acordo com o agrupamento; barh plota as barras na horizontal.\n",
        "base_de_dados['col2'].groupby(base_de_dados['col5']).mean().round(1).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj3WApOdzxjc"
      },
      "source": [
        "base_de_dados['colunas'].T.plot(kind='box'); # Plota em formato boxplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG03k4b06VNb"
      },
      "source": [
        "base_de_dados['col'].plot(kind='hist', edgecolor='black', bins= 10); # Plota um histograma com 10 barras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuOUd8neca7S"
      },
      "source": [
        "base_de_dados.filter(regex= 'P27') # Puxa da tabela todas as informações em que o Regex tiver parte ou uma palavra inteira."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H_z0JGQvg3L"
      },
      "source": [
        "base_de_dados['col3'] # Chama as informações da coluna selecionada."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr2yvCFKstxH"
      },
      "source": [
        "base_de_dados[['col6','col19']] # Chama as informações das colunas selecionadas pelo nome delas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjbODTj0uDMK"
      },
      "source": [
        "base_de_dados[base_de_dados['colunaX'] == 'M'] # Chama apenas os dados especificos da coluna selecionada."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnzZSefauDPS"
      },
      "source": [
        "base_de_dados[base_de_dados['co1'] > 4] # Chama as informações de acordo com o filtro."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ6B-qzLuDST"
      },
      "source": [
        "# Chama as info's das colunas de acordo com as condições solicitadas.\n",
        "base_de_dados[(base_de_dados['col1'] > 4) & (base_de_dados['col3'] == 'F')] #ex1\n",
        "base_de_dados.loc[base_de_dados['P3'] > 4].loc[base_de_dados['Sexo']=='F'] #ex2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ6yrS0oqUH0"
      },
      "source": [
        "# Buscando dados como SQl\n",
        "# usar f-string dentro de queries\n",
        "import pandasql as ps # !pip install pandasql\n",
        "\n",
        "filtro_idade = 30\n",
        "query = f\"\"\"select * from df where age < {filtro_idade}\"\"\"\n",
        "\n",
        "ps.sqldf(query, locals())\n",
        "\n",
        "# E se quiser a estatística descritiva por grupo?\n",
        "#df.groupby(\"Sex\")[\"Age\", \"Credit amount\", \"Duration\"].mean()\n",
        "df.groupby(\"Purpose\")[\"Age\", \"Credit amount\", \"Duration\"].mean()\n",
        "\n",
        "df.query(\" Age > 70 & Sex == 'male' \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4qi6gt7ts6"
      },
      "source": [
        "base_de_dados.loc['linha'] # Chama os valores da LINHA selecionada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4wOueW5uDUX"
      },
      "source": [
        "base_de_dados.iloc[3:,2:3] # Chama as informações da quarta linha pra frente da segunda coluna. É Indexado à posição dos dados no conjunto de dados."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCXgCpm58Vnb"
      },
      "source": [
        "base_de_dados.iloc[:,[1,7,6]] # Chama todas as linhas das colunas 1, 7 e 6 respectivamente."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx_Ck6SuuDY3"
      },
      "source": [
        "base_de_dados.mean() # Chama a média. axis=1 chamaria pelas médias das linhas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG4B1YkZstc5"
      },
      "source": [
        "base_de_dados.T # Transpõe os dados de colunas para os indices."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVlxHKBYEBJZ"
      },
      "source": [
        "base_de_dados[\"coluna1\"].value_counts() / len(base_de_dados) # distribuição das categorias da coluna selecionada em percentual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aPjNgTbEMrc"
      },
      "source": [
        "base_de_dados['col1'].value_counts() # distribuição das categorias em valores absolutos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcvXeqY5XRZD"
      },
      "source": [
        "### Testes de Hipótese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jduL73IaXYzF"
      },
      "source": [
        "O que são Testes de Hipóteses?\n",
        "\n",
        "Testes estatísticos são regras de decisão que permitem avaliar a razoabilidade das hipóteses feitas sobre os parâmetros populacionais e aceitá-las ou rejeitá-las como provavelmente verdadeiras ou falsas tendo como base uma amostra. Em outras palavras, é uma regra de decisão que ajuda a valiar hipóteses feitas sobre os parâmetros populacionais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59MFQXuSXjdU"
      },
      "source": [
        "Executando o Teste de Normalidade\n",
        "\n",
        "Muito comumente declaramos uma variável sendo normal, de forma visual, baseados apenas pela curva de sino. No entanto, podemos declará-la normal, de forma mais robusta e formal. Podemoa aplicar testes estatísticos, aceitando ou rejeitando a hipótese de uma determinada distribuição ser normal ou não."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG0-Irr1XVSc"
      },
      "source": [
        "from scipy.stats import normaltest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhgmYmOpXuPM"
      },
      "source": [
        "A função 'normaltest' testa a hipótese nula 𝐻0 de que a amostra é proveniente de uma distribuição normal, através de um teste de normalidade. É isso que temos que rejeitar ou não de acordo com a resposta de normaltest.\n",
        "Definindo a significância do teste ( 𝛼 )\n",
        "Significância padrão, com nível de confiança de 95%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpNJgURDX3As"
      },
      "source": [
        "significancia = 0.05\n",
        "stat_test, valor_p = normaltest(base_dados.coluna)\n",
        "resultado = valor_p <= significancia\n",
        "print(stat_test)\n",
        "print(valor_p)\n",
        "print(f'Rejeitamos a hipótese nula H0?' {resultado})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXp92TXyY_Mm"
      },
      "source": [
        "O H0 no nosso caso é a hipótese de que a amostra é proveniente de uma distribuição normal. A regra de rejeição é simples, o valor-p é menor ou igual a significância alfa de 5%?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_6VX1HxZytu"
      },
      "source": [
        "Se valor-p num teste de normalidade é de 90%, portanto, não rejeitamos H0. Essa estatística se traduz em não rejeitar a hipótese de a variável ser normalmente distribuída."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ajPFP3_2Am2"
      },
      "source": [
        "### Normalização de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYM9qlnG2DRF"
      },
      "source": [
        "Obs: Àrvores de Decisão não precisam de nenhum tipo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6jwY3mdT4r7"
      },
      "source": [
        "# METODO ARTESANAL\n",
        "#Normalizando valores entre 400 e 900\n",
        "dados['CreditScore'] = dados['CreditScore']/1000 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu9_rRadTugU"
      },
      "source": [
        "# Normalizando a idade\n",
        "import numpy as np\n",
        "media = np.mean(dados['Age'])\n",
        "desvio = np.std(dados['Age'])\n",
        "dados['Age'] = (dados['Age'] - media)/desvio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIenYZ6DzvXB"
      },
      "source": [
        "# MinMax - tranforma os dados numa escala entre zero e 1 quando usar?  \n",
        "- quando não pode ter numero negativo\n",
        "- quando não sabemos a distribuição dos dados\n",
        "- muito utlizado em Redes Neurais e processamento de imagens\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dados_norm = scaler.fit_transform(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_FltBu0IU0E"
      },
      "source": [
        "# Z-score (ESCALA PADRÃO) deve ser utilizado na maioria dos casos, tem dados negativos, precisa tratar outliers antes\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "sc = StandardScaler()\n",
        "rs = RobustSacaler() # RobustScaler é menos sujeito a valores discrepantes.\n",
        "\n",
        "aux0 = sc.fit_transform(titanic[['Age', 'Fare']]) # Faz a normalização dos dados\n",
        "aux1 = pd.DataFrame(aux0, columns=['Idade','Tarifa']) # Cria novas colunas com dados normalizados, trocar nome das colunas\n",
        "titanic = pd.concat([titanic, aux1], axis=1) # Coloca as novas colunas na base de dados\n",
        "titanic.drop(['Age', 'Fare'], axis=1, inplace=True) # Elimina as colunas antigas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhdJPTbbPm3P"
      },
      "source": [
        "5º **IQR:**Quando uma variável não segue uma distribuição normal, ao invés de usar o método z_score \n",
        "(que assume uma distribuição normal dos dados e confia na média e desvio padrão dos dados para identificar os outliers),\n",
        "aplica-se a regra do box plot (IQR interquartile range)\n",
        "\n",
        "* Ordenar os dados de forma crescente\n",
        "* Calcular Q1 e Q3\n",
        "* Encontrar IQR (Q3-Q1)\n",
        "* Definir o limite inferior Q1*1.5\n",
        "* Definir o limite superior Q3*1.5\n",
        "* Outlier é qualquer ponto fora dos limites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpar_HdNPELA"
      },
      "source": [
        "# Ordenar os dados de forma crescente\n",
        "dataset_sorted = dataset_ohe['Fare'].sort_values()\n",
        "\n",
        "# Calcular Q1 e Q3\n",
        "q1, q3= np.percentile(dataset_sorted,[25,75])\n",
        "\n",
        "# Encontrar IQR (Q3-Q1)\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Definir o limite inferior Q1*1.5\n",
        "limite_inferior = q1 -(1.5 * iqr)\n",
        "\n",
        "# Definir o limite superior Q3*1.5\n",
        "limite_superior = q3 +(1.5 * iqr)\n",
        "\n",
        "print('q1={} | q3={} | iqr={} | limite inferior={} | limite superior={}'.format(q1,q3,iqr,limite_inferior, limite_superior))\n",
        "\n",
        "# Identificando os outliers\n",
        "dataset_ohe['is_outlier_fare'] = np.where(dataset_ohe['Fare'] < limite_inferior, 1, 0)\n",
        "dataset_ohe['is_outlier_fare'] = np.where(dataset_ohe['Fare'] > limite_superior, 1, dataset_ohe['is_outlier_fare'])\n",
        "print('{} registros marcados como outliers'.format(len(dataset_ohe[dataset_ohe['is_outlier_fare'] == 1]))) \n",
        "\n",
        "# Salva para uso futuro no pipeline de produção\n",
        "data = {'q1': [q1], 'q3': [q3], 'iqr': [iqr], 'limite_inferior': [limite_inferior], 'limite_superior': [limite_superior]}\n",
        "df_iqr = pd.DataFrame(data = data)\n",
        "df_iqr.to_csv('df_iqr.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRAbSrCArzLl"
      },
      "source": [
        "Análise de componente principal, ou PCA, é um método de redução de dimensionalidade frequentemente usado para reduzir a dimensionalidade de grandes conjuntos de dados, transformando um grande conjunto de variáveis em um menor que ainda contém a maior parte das informações do grande conjunto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohs0kRMlrugr"
      },
      "source": [
        "# PCA \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(data)\n",
        "data_scaled = pd.DataFrame(X_scaled, columns=data.columns)\n",
        "data_scaled.head()\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_pca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Vd3J5GIU0G"
      },
      "source": [
        "### Teste de Normalidade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tdqr2SdIU0G"
      },
      "source": [
        "# QQPlot\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "stats.probplot(dados, fit=True,   plot=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehN_xZ3NIU0I"
      },
      "source": [
        "from scipy import stats\n",
        "# Teste de Shapiro-Wilk (teste de hipótese)\n",
        "stats.shapiro(dados)\n",
        "# Os dados estão normalmente distribuídos quando 'p-value' está acima de 0.05."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phzWFHFv7DOQ"
      },
      "source": [
        "### Transformando dados Categóricos em numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgZzGCu8I5su"
      },
      "source": [
        "dados['smoker'] = dados['smoker'].map({'yes': 1, 'no': 0}) # Troca variaveis binárias de string para 0 e 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTIZgipi7OPH"
      },
      "source": [
        "dados['job'] = dados['job'].map({'management': 0, 'blue-collar':1, 'technician': 2, 'admin.': 3, 'services': 4, 'retired': 5, 'unknown': 6}) \n",
        "dados['contact'] = dados['contact'].map({'cellular': 1, 'unknown':0, 'telephone': 2})\n",
        "dados['month'] = dados['month'].map({'jan': 0, 'feb': 1,'mar': 2, 'apr': 3, 'may': 4, 'jun': 5,'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9,'nov': 10, 'dec': 11,})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUWFkNrsJjnm"
      },
      "source": [
        "### Seleção de Features (variáveis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtYBdGlvxVm_"
      },
      "source": [
        "A Feature Selection deve ser feita depois da etapa de pré-processamento dos dados. O objetivo é selecionar as melhores variáveis como possíveis variáveis preditoras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvXfMYY1xXVj"
      },
      "source": [
        "A etapa de feature selection ajuda a reduzir o overfitting, aumenta a acurácia do modelo e reduz o tempo de treinamento.\n",
        "\n",
        "Tipos de Algoritmos e Métodos\n",
        "\n",
        "Filter Methods : Métodos de seleção que utiliza medidas estatísticas para atribuir um score para cada feature. As features são classificadas pelo score para serem mantidas ou removidas do modelo. Normalmente se usam testes univariados que consideram a independência da feature com a variável alvo. Exemplo: chi squared, scores com coeficiente de correlação.\n",
        "Wrapper Methods : Métodos de seleção que selecionam um conjunto de features, onde diferentes combinações são preparadas, avaliadas e comparadas. Um modelo preditivo é usado para avaliar a combinação de features a atribuir um score baseado em uma acurácia de modelo. Exemplo: algoritmo RFE\n",
        "Embedded Methods : Métodos Embedded aprendem quais feature melhor contribuiem para a acurácia do modelo no momento de construção do modelo. Exemplo: métodos de penalização, algoritmos Lasso, Elastic NEt e Ridge Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quUR4DcFxagQ"
      },
      "source": [
        "Qual Método utilizar?\n",
        "\n",
        "Tente usar o RFE caso tenha recursos computacionais para isso.\n",
        "Se estiver trabalhando com Classificação e as features forem numéricas utilize f_classif ou mutual_info_classif.\n",
        "Se estiver trabalhando com Regressão e as features forem numéricas utilize f_regression ou mutual_info_regression.\n",
        "Caso esteja trabalhando com features categóricas utilize chi2\n",
        "Automatize essa etapa com Pipelines para evitar erros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S90ITfVbxpoT"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "f_classif = SelectKBest(score_func=f_classif, k=4)\n",
        "fit = f_classif.fit(X,y)\n",
        "features = fit.transform(X)\n",
        "cols = fit.get_support(indices=True)\n",
        "dados.iloc[:,cols].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4AOeOoiIzuG"
      },
      "source": [
        "import numpy as np # Verificando a correlação das variáveis com a target\n",
        "correlacao = np.corrcoef(X, y)\n",
        "correlacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-dSUYvw1mtC"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X = dados.drop('Target', axis = 1)\n",
        "y = dados['Target']\n",
        "\n",
        "modelo_base = RandomForestClassifier(max_depth = 3) \n",
        "modelo_base.fit(X, y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiguOHw-Jr9G"
      },
      "source": [
        "modelo_base.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgrt8tf0-oMz"
      },
      "source": [
        "variaveis = pd.DataFrame()\n",
        "variaveis['variavel'] = X.columns\n",
        "variaveis['importância'] = modelo_base.feature_importances_\n",
        "variaveis.sort_values(by = 'importância', ascending = True, inplace = True)\n",
        "variaveis.set_index('variavel', inplace = True)\n",
        "variaveis.plot(kind='barh', figsize=(8, 5));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huqq71iw7fKf"
      },
      "source": [
        "### Dummyficando as colunas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvx1GucH7ihu"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dados = pd.get_dummies(dados, columns = ['job', 'marital', 'education', 'contact', 'month', 'poutcome'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1WCUuHqA8HL"
      },
      "source": [
        "variaveis_cat = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService'] \n",
        "\n",
        "treino = pd.get_dummies(treino, columns = variaveis_cat, drop_first = True)\n",
        "\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HqiD7t273EP"
      },
      "source": [
        "# Transformando dataset em Matriz para Machine Learning\n",
        "X = dados.iloc[:,0:6].values # todos os valores de todas as colunas da 0 até a 5\n",
        "y = dados.iloc[:,6].values # a coluna da classe. 'target'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DQDTtTfpEzv"
      },
      "source": [
        "### Códigos para manipulação (binning) e exploração de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKVJD7C5IU0N"
      },
      "source": [
        "dados['colunaX'] = dados['colunaX'].map({'antigo':'novo', 'antigo': 1, 458: 'novo'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uWJoh_sstrW"
      },
      "source": [
        "base_de_dados.sample(3) # Mostra uma amostra aleatória de três linhas ao invés de usar head ou tale."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwmfVPVLIU0N"
      },
      "source": [
        "#Somando todos os valores presentes na Series por 2\n",
        ">>> s.add(2)\n",
        "#Subtraindo 2 de todos os valores\n",
        ">>> s.sub(2)\n",
        "#Multiplicando todos os valores por 2\n",
        ">>> s.mul(2)\n",
        "titanic['fulanos'] = titanic['SibSp'].mul(100)\n",
        "#Dividindo valores por 2\n",
        ">>> s.div(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JficVtz8stlu"
      },
      "source": [
        "base_de_dados.info() # Mostra informações sobre o dados faltantes e do formato dos dados das colunas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mDhpv09XlJY"
      },
      "source": [
        ".unstack().T # Cria duas colunas selecionadas em uma 'mini base de dados'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1d3dK_Y4PaR"
      },
      "source": [
        "dados2 = base_de-dados[['Fare','Sex_male', 'Titulo_Mr']] # Seleciona algumas colunas apenas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo_P8Y55stop"
      },
      "source": [
        "base_de_dados.shape # Mostra a qtde de linhas e colunas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5NZY9-Ks_u"
      },
      "source": [
        "base_de_dados[\"coluna\"].value_counts() # Conta os valores da coluna selecionada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewOynVbn6VQI"
      },
      "source": [
        "base_de_dados.concat(['basedados1','basedados2']) #Concatena dois conjuntos de dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MWiaheR_2h5"
      },
      "source": [
        "pd.concat([dados, dados2], axis=1) # JUNTA DUAS TABELAS EM QUE AS COLUNAS FICAM LADO A LADO."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfUV7hKhEweS"
      },
      "source": [
        "base_de_dados['novaColuna'] = variavelNova # Adiciona no conjunto uma nova coluna com os dados novos."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uDjqsom2dIK"
      },
      "source": [
        "# Busca das informações da coluna selecionada\n",
        "agrupado = base_de_dados.groupby(['coluna']).size()\n",
        "agrupado\n",
        "\n",
        "# padronizando uma informação\n",
        "base_de_dados.loc[base_de_dados['Genero'] ==  'M', 'Genero'] = \"Masculino\"\n",
        "\n",
        "# padronizando varias informações\n",
        "base_de_dados.loc[base_de_dados['Genero'].isin( ['Fem','F']), 'Genero'] = \"Feminino\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFK7vHgEIU0Q"
      },
      "source": [
        "#Pré-processamento inicial das variáveis\n",
        "\n",
        "dic = {'A11': 'negativo', 'A12': '[0-200)', 'A13': '200+', 'A14': 'sem conta'}\n",
        "dados['conta'] = dados['conta'].map(dic)\n",
        "\n",
        "\n",
        "dic = {'A30': 'primeira vez', 'A31': 'creditos quitados', 'A32': 'pagamento em dia', \n",
        "       'A33': 'já atrasou pagamentos', 'A34': 'conta crítica'}\n",
        "dados['historico'] = dados['historico'].map(dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZzRc36nUIoK"
      },
      "source": [
        "conjunto = ['dado1', 'dado2', 'dado3', '...', 'dadox']\n",
        "colunas = ['P1','P2','P3','P4']\n",
        "nova_base = pd.DataFrame(nova_base, index=conjunto, columns=colunas) # Cria um novo conjunto de dados indexado pelo conjunto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8J-whLP3jVW"
      },
      "source": [
        "base_de_dados['coluna1'] = base_de_dados['coluna1'].astype('float64') # Convertendo coluna string em float"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-lpd9RWQ_xE"
      },
      "source": [
        "base_de_dados = base_de_dados.drop(0) # Exclui a linha selecionada nesse caso, a primeira"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm-wc0_tcElO"
      },
      "source": [
        "base_de_dados.drop(base_de_dados.loc[base_de_dados['nome_coluna'] < 1000].index, inplace=True) # Seleciona e exclui linhas selecionadas com condições."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB6d5AbKQ_kt"
      },
      "source": [
        "# excluindo as colunas das variaveis selecionadas\n",
        "dados.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evI0nv23KtFE"
      },
      "source": [
        "base_de_dados.to_csv('nome-da-base.csv', sep= ',') # Salva a base de dados tratada em csv."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pujO-uvGHrx2"
      },
      "source": [
        "from IPython.display import Image # Colocando imagem no notebook\n",
        "Image('Treinamento.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwNlj62XV4l9"
      },
      "source": [
        "### Dados nulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk6MbpG_yRiw"
      },
      "source": [
        "dataset.duplicated().sum() # conta linhas duplicadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVERbfRgyRdq"
      },
      "source": [
        "base_de_dados[base_de_dados.duplicated()] # Pesquisando dados duplicados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEgdt8A_yRap"
      },
      "source": [
        "base_de_dados.drop_duplicates(keep='last') # apagando dados duplicados, mantendo o último"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llb_hCCYyZt5"
      },
      "source": [
        "dataset.isnull().sum() # Conta dados nulos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ukn58VGyBfB"
      },
      "source": [
        "base_de_dados.isnull().sum().sort_values(ascending=False) # Buscar por dados NaN (faltantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULOV8mqBDDUb"
      },
      "source": [
        "import missingno as msno # Se houver dados faltantes, verificando aonde estão\n",
        "msno.matrix(dados, figsize= (10,6), color= (0, 0.1, 0.25), sparkline=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJCy0BMbIU0U"
      },
      "source": [
        "# substituindo campos vazios pela media\n",
        "nulos = ['Resource Allocation','Mental Fatigue Score','Burn Rate']\n",
        "dados[nulos] = dados[nulos].replace({np.nan: dados['Resource Allocation'].mean(), \n",
        "                                     np.nan: dados['Burn Rate'].mean(), \n",
        "                                     np.nan: dados['Mental Fatigue Score'].mean()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVijHbDslKdV"
      },
      "source": [
        "base_de_dados.isnull().sum()\n",
        "# substituindo campos vazios pela mediana\n",
        "base_de_dados['coluna'].describe() # código que mostra algumas informações estatísticas, entre elas a mediana\n",
        "mediana = sts.median(base_de_dados['coluna']) # crição da variável mediana, que será preenchida nos campos vazios\n",
        "base_de_dados['coluna'].fillna(mediana, inplace=True)\n",
        "base_de_dados.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgZR3pPJ0jZk"
      },
      "source": [
        "# localizando a moda da coluna\n",
        "agrupado = base_de_dados.groupby(['coluna']).size()\n",
        "agrupado\n",
        "# substituindo campos vazios pela moda\n",
        "base_de_dados['coluna'].fillna('Moda', inplace=True)\n",
        "#Verificamos se NAN não existem mais\n",
        "base_de_dados['Salario'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfDRoaVO3y2B"
      },
      "source": [
        "Binning é a junção das linhas mais raras no seu dataset. Com isso, reduz as complexidades das características. Melhorando a performance do modelo. Pode ser usado em variáveis categóricas e numéricas e pode utilizar a categoria outros para baixa cardinalidade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAuLXc-zoB-L",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "print(base_de_dados['coluna'].value_counts()) # value_counts() conta as qtes por nome\n",
        "plt.figure()\n",
        "grafico = sns.countplot('coluna', data=base_de_dados) # countplot é tipo value_counts dos graficos\n",
        "grafico.tick_params(axis='x', rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbKA5vg0xcT"
      },
      "source": [
        "# dados categoricos necessitam ser substituidos pela moda:\n",
        "agrupado = base_de_dados.groupby(['Estado']).size() # nesse exemplo o valor é RS\n",
        "# no exemplo, nosso cliente atua apenas na região sul e portanto existem dados que precisam ser tratados\n",
        "base_de_dados.loc[base_de_dados['Estado'].isin( ['RP','SP','TD']), 'Estado'] = \"RS\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_46WT-2zVMG"
      },
      "source": [
        "base_de_dados['smoker'] = base_de_dados['smoker'].map({'yes': 1, 'no': 0}) # Troca variaveis binárias de string para 0 e 1. Pode utilizar para palavras tambem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpqhNSDyxcf"
      },
      "source": [
        "base_de_dados['coluna'] = base_de_dados['coluna'].str.replace('R$','') # substitui cifrão por espaço nos dados da coluna selecionada\n",
        "base_de_dados['coluna'] = base_de_dados['coluna'].str.replace(',','') # preco precisa ser com ponto\n",
        "base_de_dados['coluna'] = base_de_dados['coluna'].astype(np.float32, copy=False) #conversão p/float"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2K-fAD011ZK"
      },
      "source": [
        "# discretização da idade (escolha arbitraria dos cortes)\n",
        "cortes = [0, 24, 30, 40, 100] # faixas de idade\n",
        "nomes = ['[18,24]', '[25,30]', '[31,40]', '[41,50]']\n",
        "\n",
        "# comando cut vai cortar o banco de dados nas faixas acima e colocar nas devidas novas colunas (nomes)\n",
        "dados['idade'] = pd.cut(dados[\"('P1', 'age')\"], bins = cortes, labels = nomes) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40MH1w-S8hD"
      },
      "source": [
        "# criando variáveis mais convenientes\n",
        "# os valores do lado esquerdo sao os que estão na coluna original e a direita sao os novos valores\n",
        "\n",
        "# coluna empresas\n",
        "tammap = { 'de 1 a 100': 'Pequena',\n",
        "           'de 101 a 1000': 'Média',\n",
        "           'Acima de 1000': 'Grande'}\n",
        " \n",
        "# coluna salarios\n",
        "salamap = {    'Menos de R$ 1.000/mês': 1000,\n",
        "      'de R$ 1.001/mês a R$ 2.000/mês': 1500, \n",
        "       'de R$ 2.001/mês a R$ 3000/mês': 2500,\n",
        "      'de R$ 3.001/mês a R$ 4.000/mês': 3500,\n",
        "               'Acima de R$ 5.000/mês': 5000}\n",
        "\n",
        "# criando novas colunas com as informações alteradas: \n",
        "dados['salario'] = dados[\"('P16', 'salary_range')\"].map(salamap)  \n",
        "dados['tamanho_da_empresa'] = dados[\"('P12', 'workers_number')\"].map(tammap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFO3W4ylMxNH"
      },
      "source": [
        "#Exemplo : temos o endereço '917, 1st St, Dallas, TX 75001' na coluna Adress de um banco de dados:\n",
        "# Usando o apply()\n",
        "def get_city(adress):\n",
        "  return address.split(,)[1]\n",
        "\n",
        "def get_state(address):\n",
        "  return address.split(,)[2].split(' ')[1]\n",
        "  \n",
        "base_de_dados['Cidade'] = base_de_dados['Address'].apply(lambda x: f'{get_city(x)} ({get_state(x)})') \n",
        "# função que retira informação entre as vírgulas e salva em uma nova coluna.\n",
        "# Vai retornar na coluna Cidade apenas a palavra 'Dallas (TX)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2AsMg9HEGkP"
      },
      "source": [
        "# Agrupando diversos valores numa categoria como OUTROS\n",
        "nome = pd.read_csv('train.csv', usecols=['Name'])\n",
        "titulacao = []\n",
        "for i in range(nome.shape[0]):\n",
        "    titulacao.append(nome.iloc[i,0].split(', ')[1].split('. ')[0])\n",
        "\n",
        "tt = []\n",
        "for i in range(nome.shape[0]):\n",
        "    if titulacao[i] in ['Mr','Miss','Mrs','Master']:\n",
        "        tt.append(titulacao[i])\n",
        "    else:\n",
        "        tt.append('Outros')\n",
        "titanic['Titulo'] = tt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdXCtgh50xhr"
      },
      "source": [
        "def auxiliar(x):\n",
        "    if x == 0:\n",
        "        return 'Zerada'\n",
        "    elif x < 100000:\n",
        "        return 'Até 100k'\n",
        "    elif x < 150000:\n",
        "        return '100k - 150k'\n",
        "    else:\n",
        "        return '150k+'\n",
        "\n",
        "dados['Balance'] = dados['Balance'].apply(auxiliar)\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hex-5md0xUT"
      },
      "source": [
        "# AGRUPAMENTO DE CATEGORIAS\n",
        "def auxiliar(x):\n",
        "    if x <= 3:\n",
        "        return '0-3'\n",
        "    elif x <= 6:\n",
        "        return '4-6'\n",
        "    else:\n",
        "        return '7-10'\n",
        "\n",
        "dados['Tenure'] = dados['Tenure'].apply(auxiliar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PJPY_D0oB-L",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "#A sugestão é, agrupar valores muito pequenos deixando os dados mais compactos e indo direto nas infos que importam:\n",
        "tabela_outros = dataset['coluna'].value_counts()  # agrupando tudo novamente so que numa variavel\n",
        "colunas_agrupar = [] # lista vazia\n",
        "\n",
        "for i in tabela_outros.index:\n",
        "    if tabela_outros[i] < x:     # x é a qtde deseja agrupar\n",
        "        colunas_agrupar.append(i)\n",
        "print(colunas_agrupar) # para ler as colunas que foram para a variavel\n",
        "\n",
        "#Agora, subtituir esses nomes com poucos valores por um só, agrupando-os:\n",
        "for i in colunas_agrupar:\n",
        "    base_de_dados.loc[base_de_dados['coluna']== i, 'coluna']== 'OUTROS'\n",
        "\n",
        "# Reimprimindo os dados dessa coluna para ver se ficou melhor:\n",
        "print(base_de_dados['coluna'].value_counts())\n",
        "\n",
        "plt.figure()\n",
        "grafico = sns.countplot('coluna', data=base_de_dados) # countplot é um 'value_counts' dos graficos\n",
        "grafico.tick_params(axis='x', rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkwKyyOum89h"
      },
      "source": [
        "### Outliers Numéricos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O18gbSfx2-Xw"
      },
      "source": [
        "Para tratar outliers dos dados não existe uma regra universal, porém o setup que ajusta bem no processo de ML é utilizar 2 desvios padrão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRNLoHWdgLX"
      },
      "source": [
        "# localizando dados outliers basicos como idade negativa etc\n",
        "base_de_dados.loc[ (base_de_dados['coluna'] < 0 'ou outro parametro') | (base_de_dados['Idade'] >= 'parametro') ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbrLPAafdgLX"
      },
      "source": [
        "# substituindo os outliers pela mediana da variavel\n",
        "mediana = sts.median(dataset['coluna'])\n",
        "base_de_dados.loc[ (base_de_dados['coluna'] < 0 'ou outro parametro') | (base_de_dados['Idade'] >= 'parametro') ] = mediana"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdedTojGdgLX",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "# Verificar se tem algum valor fora do critério (de dois desvios):\n",
        "base_de_dados.loc[base_de_dados['coluna'] >=  2 * desv ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx8VlgALdgLX",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "# Se houver: calculando o desvio padrão dos valores de uma coluna:\n",
        "desvio = sts.stdev(dataset['coluna'])\n",
        "# Realizar a subst. de outliers pela mediana\n",
        "base_de_dados.loc[base_de_dados['coluna'] >=  2 * desvio, 'coluna'] = mediana"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drZ0zu7jdgLY",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "#visualizar \n",
        "base_de_dados.loc[(base_de_dados['Idade'] <  0 )  | ( base_de_dados['Idade'] >  120) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR3mFtHour_h"
      },
      "source": [
        "# TRATANEDO OUTLIERS POR QUANTIS\n",
        "dados['Fare'].plot(kind = 'box');\n",
        "top = dados['Fare'].quantile(0.90)\n",
        "dados.loc[dados['Fare'] > top, 'Fare'] = top\n",
        "dados['Fare'].plot(kind = 'box');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWx7KJtdgLd"
      },
      "source": [
        "### Conversões"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNImYZTpdgLe"
      },
      "source": [
        "#Convert DAYS to YEARS\n",
        "cust_data['EMP_YEARS'] = cust_data.DAYS_EMPLOYED/365\n",
        "cust_data['AGE'] = cust_data.DAYS_BIRTH/365\n",
        "cust_data.drop([\"DAYS_BIRTH\",\"DAYS_EMPLOYED\"],axis = 1,inplace = True)\n",
        "cust_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzGNaLLnIU0a"
      },
      "source": [
        "# Conversão dos atributos que estão no formato string para formato de data: ANO-MÊS\n",
        "dateparse = lambda dates: datetime.strptime(dates, '%Y-%m')\n",
        "dataset = pd.read_csv('tua_planilha.csv', parse_dates = ['coluna_data'],\n",
        "                   index_col = 'coluna_data', date_parser = dateparse)\n",
        "dataset #para verificar se mudou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkj5gaDcIU0a"
      },
      "source": [
        "# função contador total de dias a partir de uma coluna de data da base\n",
        "def create_days_count(data):\n",
        "    return (current_date - data[\"Date of Joining\"])\n",
        "\n",
        "# Contando os dias\n",
        "df = dados\n",
        "current_date = pd.to_datetime('today')  \n",
        "# Adicionando o contador de dias na base de dados\n",
        "df[\"days_count\"] = df.apply(create_days_count, axis=1).dt.days"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAWe96jmPK9Y"
      },
      "source": [
        "# Conversão de datas\n",
        "dados['dtIncioObra'] = pd.to_datetime(dados5['dtInicio'], dayfirst=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ue7KdiNC55"
      },
      "source": [
        "from datetime import datetime\n",
        "# Conversão dos atributos que estão no formato string para formato de data: ANO-MÊS\n",
        "dateparse = lambda dates: datetime.strptime(dates, '%Y-%m')\n",
        "dataset = pd.read_csv('tua_planilha.csv', parse_dates = ['coluna_data'],\n",
        "                   index_col = 'coluna_data', date_parser = dateparse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxZU3I3gM3gX"
      },
      "source": [
        "base_de_Dados['colunadadata'] = pd.to_datetime(base_de_Dados['colunadadata']) #Converte a data da coluna que estiver em outro formato"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRJO0CXDNwyH"
      },
      "source": [
        "base_de_Dados['hora'] = base_de_Dados['colunadadata'].dt.hour # cria uma coluna mostrando a hora da coluna original\n",
        "base_de_Dados['minuto'] = base_de_Dados['colunadadata'].dt.minute # cria uma coluna mostrando os minutos da coluna original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUfia-09IU0b"
      },
      "source": [
        "### Validação Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNVh68QhIU0b"
      },
      "source": [
        "# Hold-out\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Vr-QigIU0b"
      },
      "source": [
        "# K-fold estratificado\n",
        "from sklearn.model_selection import cross_validate # para cruzar validações dos modelos\n",
        "from sklearn.model_selection import StratifiedKFold # estratificando amostra do Kfold\n",
        "validacao = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cALTHXaMIU0c"
      },
      "source": [
        "### Modelos de ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMxbwrCIU0c"
      },
      "source": [
        "# Alguns modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier \n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg59BIahIU0c"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QheznAiMIU0c"
      },
      "source": [
        "# Utilização do algoritmo ExtraTreesClassifier para identificar as variaveis mais importantes \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "forest = ExtraTreesClassifier()\n",
        "forest.fit(X_treinamento, y_treinamento)\n",
        "importancias = forest.feature_importances_\n",
        "importancias #Ele responde com o valor que cada coluna tem de importancia. \n",
        "# Note que não é em ordem do maior para o menor mas sim na ordem que as colunas estão dispostas na nossa base de dados."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzu7I_u4IU0d"
      },
      "source": [
        "#geração da matriz de confusão e cálculo da taxa de acerto e erro:\n",
        "confusao = confusion_matrix(y_teste, previsoes)\n",
        "confusao\n",
        "# MATRIZ DE CONFUSÃO\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"Matriz de Confusão : \\n\" + str(confusion_matrix(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdr6Pqn8IU0d"
      },
      "source": [
        "### Dados desbalanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJSs5FEIU0d"
      },
      "source": [
        "# Verificando se a classe está desbalanceada\n",
        "y.value_counts().plot.pie(autopct='%.2f');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fIzOu0hIU0d"
      },
      "source": [
        "#### Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbHebRj5IU0d"
      },
      "source": [
        "Simplesmente vai jogar fora grande parte dos dados, deixando as classes balanceadas.\n",
        "Ex: Aqui, temos 500 dados 0 para 70k 1, o undersampling vai descartar todos os dados até chegar em 500/500 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCrpwuAbIU0e"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy= 1) # para numeros\n",
        "#rus = RandomUnderSampler(sampling_strategy='not minority') # para strings\n",
        "X_us, y_us = rus.fit_resample(X, y)\n",
        "\n",
        "# Conferindo o balanço\n",
        "ax = y_us.value_counts().plot.pie(autopct='%2.f')\n",
        "_ = ax.set_title('Under Sampling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl1jEGQNIU0e"
      },
      "source": [
        "ou"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycvXsmdlIU0e"
      },
      "source": [
        "def UnderSampling(dados, under = 1):\n",
        "    classe0 = dados[dados['Class'] == 0]\n",
        "    classe1 = dados[dados['Class'] == 1]\n",
        "\n",
        "    amostra0 = classe0.sample(under * classe1.shape[0])\n",
        "    under = pd.concat([amostra0, classe1])\n",
        "\n",
        "    return under"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jothf-6DIU0e"
      },
      "source": [
        "# Verificando o trade-off em vários tamanhos de dados\n",
        "under1 = UnderSampling(dados, 1) # Amostra 1 pra 1.\n",
        "under2 = UnderSampling(dados, 2) # Amostra 2 pra 1.\n",
        "under5 = UnderSampling(dados, 5) # Amostra 5 pra 1.\n",
        "under10 = UnderSampling(dados, 10) # Amostra 10 pra 1.\n",
        "under25 = UnderSampling(dados, 25) # Amostra 25 pra 1.\n",
        "under40 = UnderSampling(dados, 40) # Amostra 40 pra 1. Esse pode ser o melhor.\n",
        "underX = UnderSampling(dados, X) # Amostra X pra 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnijrUlZIU0f"
      },
      "source": [
        "Agora, modelando novamente, utilizando Pycaret e o novo banco de dados undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evMoOpw2IU0f"
      },
      "source": [
        "modelagem = setup(data= under1,\n",
        "                  target= 'Class',\n",
        "                  test_data= teste,\n",
        "                  normalize= True)\n",
        "\n",
        "# Selecionando alguns bons modelos para problemas de fraude\n",
        "modelos = ['et', 'rf', 'lightgbm', 'dt', 'lr', 'svm']\n",
        "\n",
        "# Modelando\n",
        "modelo = compare_models(include= modelos, sort= 'F1')\n",
        "pred = predict_model(modelo)\n",
        "\n",
        "# Utilizar outros 'undersamplings' para detectar o melhor modelo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gho7Q8uwIU0f"
      },
      "source": [
        "#### Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4C7q2kLIU0f"
      },
      "source": [
        "Replica a classe minoritária até balancear os dados. Simplesmente REPETE os dados mesmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHduu9vGIU0g"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#ros = RandomOverSampler(sampling_strategy=1) # para float\n",
        "ros = RandomOverSampler(sampling_strategy='not majority') # para string\n",
        "X_os, y_os = ros.fit_resample(X, y)\n",
        "\n",
        "# plotando gráfico\n",
        "ax = y_os.value_counts().plot.pie(autopct='%.2f')\n",
        "_ = ax.set_title('Over Sampling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZe2SQuVIU0g"
      },
      "source": [
        "ou"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhUzpVMzIU0g"
      },
      "source": [
        "def UnderOverSampling(dados, , under =1, over = 1):\n",
        "    classe0 = dados[dados['Class'] == 0]\n",
        "    classe1 = dados[dados['Class'] == 1]\n",
        "\n",
        "    amostra0 = classe0.sample(under * classe1.shape[0])\n",
        "    amostra1 = pd.concat([classe1] * over, ignore_index= True)\n",
        "    tudo = pd.concat([amostra0, amostra1])\n",
        "\n",
        "    return tudo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBHGLYcqIU0g"
      },
      "source": [
        "# Verificando o trade-off em vários tamanhos de dados\n",
        "underover1 = UnderOverSampling(dados, under= 20, over= 4)\n",
        "underover2 = UnderOverSampling(dados, under= 20, over= 8)\n",
        "underover3 = UnderOverSampling(dados, under= 20, over= 12)\n",
        "underover4 = UnderOverSampling(dados, under= 20, over= 16)\n",
        "underover5 = UnderOverSampling(dados, under= 20, over= 20) # Melhor modelo neste problema. Recall 1 prec. 0.79\n",
        "underoverX = UnderOverSampling(dados, under= 20, over= Xvezes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rnvs-oQIU0g"
      },
      "source": [
        "# modelando\n",
        "modelagem = setup(data= underover1,\n",
        "                  target= 'Class',\n",
        "                  test_data= teste,\n",
        "                  normalize= True)\n",
        "\n",
        "# Selecionando alguns bons modelos para problemas de fraude\n",
        "modelos = ['et', 'rf', 'lightgbm', 'dt', 'lr', 'svm']\n",
        "\n",
        "# Modelando\n",
        "modelo = compare_models(include= modelos, sort= 'F1')\n",
        "pred = predict_model(modelo)\n",
        "\n",
        "# Utilizar outros 'undersamplings' para detectar o melhor modelo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI9gOs7VIU0h"
      },
      "source": [
        "#### Outras técnicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVNYWao8IU0h"
      },
      "source": [
        "Considerar técnicas mais robustas para esse propósito:\n",
        "\n",
        "* **Near Miss** para undersamplig\n",
        "* **SMOTE** para oversampling -- tem no pycaret\n",
        "\n",
        "\n",
        "- Ler as bibliotecas imblearn e pycaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBf1Lut3IU0h"
      },
      "source": [
        "### Salvando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiK5SFUXIU0h"
      },
      "source": [
        "#Comando de Salvamento da Máquina Preditiva\n",
        "import pickle \n",
        "pickle_out = open(\"maquina_preditiva.pkl\", mode = \"wb\") \n",
        "pickle.dump(maquina, pickle_out) \n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOjpQNNQIU0i"
      },
      "source": [
        ""
      ]
    }
  ]
}